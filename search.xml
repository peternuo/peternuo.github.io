<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>pytorch自动求导机制</title>
      <link href="/2022/09/16/pytorch%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC%E6%9C%BA%E5%88%B6/"/>
      <url>/2022/09/16/pytorch%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="自动求导机制">自动求导机制</h1><p><em>参考：<a href="https://zhuanlan.zhihu.com/p/148669484">Pytorch的自动求导机制与使用方法(一) - 知乎 (zhihu.com)</a></em></p><p>​ 自动求导机制是pytorch核心功能之一。</p><h2 id="求导法则">求导法则</h2><p>​ 限制：pytorch中默认只能是<strong>标量</strong>对<strong>标量/向量/矩阵</strong>求导。</p><p>​ 即只能对<span class="math inline">\(f(x)=z, f:R^n\rightarrow R\)</span>求导，其中<span class="math inline">\(x\)</span>可以通过多次复合函数得到，对<span class="math inline">\(f\)</span>求导利用链式法则： <span class="math display">\[\frac{\partial z}{\partial x}=\frac{\partial z}{\partial y}\frac{\partial y}{\partial x}\]</span> ​ 其中<span class="math inline">\(x\)</span>为叶节点，<span class="math inline">\(z\)</span>为根节点，<span class="math inline">\(y\)</span>是过程操作，并不会被收集，只是作一个传播作用。</p><p>​ pytorch中的求导法则，实则是反向传播。</p><h2 id="tensor张量操作规则">Tensor张量操作规则</h2><p>​ PyTorch中数据以张量(n维数组)的形式流动torch.Tensor可以用来创建张量。</p><p>​ 当Tensor的属性中<strong>requires_grad=True</strong>时，则系统就可以开始跟踪对此Tensor的所有操作。其中记录的每个操作求得的梯度不会保存，只有在最后的一个操作才会保存梯度。</p><p>​ 如上述的两次链式法则，只保存<span class="math inline">\(\frac{\partial z}{\partial x}\)</span>，而<span class="math inline">\(\frac{\partial z}{\partial y}\)</span>只是被当作中间值，<strong>不会保存</strong>。</p><p>​ 例：<strong>Tensor.backward()方法默认</strong>计算对计算图叶子节点的导数,中间过程的导数是不计算的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor(<span class="number">3.0</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = <span class="number">2</span>*x</span><br><span class="line">z = y**<span class="number">2</span></span><br><span class="line">f = z+<span class="number">2</span></span><br><span class="line">f.backward()</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"><span class="built_in">print</span>(y.grad)</span><br><span class="line"><span class="built_in">print</span>(z.grad)</span><br></pre></td></tr></table></figure><p>​ 输出结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="number">24.</span>)</span><br><span class="line"><span class="literal">None</span></span><br><span class="line"><span class="literal">None</span></span><br></pre></td></tr></table></figure><p>​ pytorch在求导时候会自动构建计算图。</p><figure><img src="https://pic2.zhimg.com/v2-2df7598f799dff8acaa0686462c084b1_r.jpg" alt="preview" /><figcaption>preview</figcaption></figure><p>​ 从上图可以看出，一个Tensor中：</p><ul><li>data中保存着所存有的数据</li><li>grad中保存梯度</li><li>requires_grad表示是否开始追踪所有的操作历史</li></ul><p>​ 想要计算梯度的时候，需要调用Tensor.backward()。在调用backward()时，只有当requires_grad和is_leaf同时为真时，才会计算节点的梯度值。</p><p>​ 例：pytorch只能标量对其他进行求导。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span>:</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.ones(<span class="number">2</span>,<span class="number">2</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = x+<span class="number">2</span><span class="comment"># y 为非标量</span></span><br><span class="line"><span class="built_in">print</span>(x.is_leaf, y.is_leaf)</span><br><span class="line"><span class="built_in">print</span>(y.requires_grad)</span><br><span class="line">y.backward()</span><br><span class="line">ouput:</span><br><span class="line">&lt;&lt;&lt;<span class="literal">True</span> <span class="literal">False</span></span><br><span class="line">&lt;&lt;&lt;<span class="literal">True</span></span><br><span class="line">&lt;&lt;&lt;RuntimeError: grad can be implicitly created only <span class="keyword">for</span> scalar outputs</span><br><span class="line">    </span><br><span class="line"><span class="comment"># y为非标量，所以不符合y.requires_grad=True，所以无法求导</span></span><br><span class="line"></span><br><span class="line">z = y * y * <span class="number">3</span></span><br><span class="line">out = z.mean()</span><br><span class="line"><span class="built_in">print</span>(out)</span><br><span class="line"><span class="built_in">print</span>(out.requires_grad)</span><br><span class="line">out.backward()</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line">output:</span><br><span class="line">&lt;&lt;&lt;tensor(<span class="number">27.</span>, grad_fn=&lt;MeanBackward0&gt;)</span><br><span class="line">&lt;&lt;&lt;<span class="literal">True</span></span><br><span class="line">&lt;&lt;&lt;tensor([[<span class="number">4.5000</span>, <span class="number">4.5000</span>],</span><br><span class="line">        [<span class="number">4.5000</span>, <span class="number">4.5000</span>]])</span><br></pre></td></tr></table></figure><p>​ 求导过程如下：</p><p>​ 令<span class="math inline">\(out=o\)</span>，由于 <span class="math display">\[o=\frac{1}{4}\sum z_i=\frac{1}{4}\sum 3(x_i)+2\]</span> ​ 所以 <span class="math display">\[\frac{\partial o}{\partial x_i}|_{x_i=1}=\frac{9}{2}=4.5\]</span></p><p>​ 例：对<span class="math inline">\(y=x^3\)</span>，对<span class="math inline">\(x=2\)</span>进行求导</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.autograd</span><br><span class="line"></span><br><span class="line">x = torch.tensor([<span class="number">2</span>,<span class="number">0</span>],requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x= &quot;</span>,x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x.requires_grad= &quot;</span>, x.requires_grad)</span><br><span class="line">y = x ** <span class="number">3</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y= &quot;</span>,y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y.requires_grad = &quot;</span>, y.grad_fn)</span><br><span class="line"></span><br><span class="line">y.backward() <span class="comment">#反向传播,求解导数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x.grad = &quot;</span>, x.grad)</span><br></pre></td></tr></table></figure><p>​ 输出结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x =  tensor([<span class="number">2.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">x.requires_grad =  <span class="literal">True</span></span><br><span class="line">y =  tensor([<span class="number">8.</span>], grad_fn=&lt;PowBackward0&gt;)</span><br><span class="line">y.requires_grad =  &lt;PowBackward0 <span class="built_in">object</span> at <span class="number">0x7f3a1dac6320</span>&gt;</span><br><span class="line">x.grad =  tensor([<span class="number">12.</span>])</span><br></pre></td></tr></table></figure><h2 id="autograd类原理">autograd类原理</h2><p>​ autograd类的原理其实是利用雅可比矩阵进行计算。</p><p>​ 设函数<span class="math inline">\(f:R^n\rightarrow R^m\)</span>，其中<span class="math inline">\(f=(f_1,f_2,\dots,f_m)\)</span>，则雅克比矩阵为： <span class="math display">\[J=\left[ \frac{\partial f}{\partial x_1}\ \cdots \ \frac{\partial f}{\partial x_n} \right] =\left[ \begin{matrix}    \frac{\partial f_1}{\partial x_1}&amp;      \cdots&amp;     \frac{\partial f_1}{\partial x_n}\\    \vdots&amp;     \ddots&amp;     \vdots\\    \frac{\partial f_m}{\partial x_1}&amp;      \cdots&amp;     \frac{\partial f_m}{\partial x_n}\\\end{matrix} \right]\]</span> ​ 上面矩阵是<span class="math inline">\(f\)</span>关于<span class="math inline">\(x=(x_1,\dots,x_m)\)</span>求导。</p><p>​ 令<span class="math inline">\(l\)</span>是一个标量函数，对<span class="math inline">\(f\)</span>进行求导有： <span class="math display">\[v=[\frac{\part l}{\part f_1},\frac{\part l}{\part f_2},\cdots,\frac{\part l}{\part f_m}  ]\]</span> ​ 则<span class="math inline">\(l\)</span>对<span class="math inline">\(x\)</span>进行求导有： <span class="math display">\[\frac{dl}{dx}=J*v^T\]</span> ​ 其中对<span class="math inline">\(x_i\)</span>求偏导有： <span class="math display">\[\frac{\part l}{\part x_i}=v*J_i\]</span> ​ 其中<span class="math inline">\(J_i\)</span>表示<span class="math inline">\(J\)</span>矩阵的第<span class="math inline">\(i\)</span>列。</p><p>​ 可以看到，<span class="math inline">\(l:R^m\rightarrow R\)</span>，从神经网络的例子来理解，<span class="math inline">\(f\)</span>是隐藏层为<span class="math inline">\(m\)</span>个神经元的个数，<span class="math inline">\(l\)</span>为输出层。</p><p>​ 从损失函数理解：标量<span class="math inline">\(l\)</span>类似于MSE函数将minibatch平均为一个平均loss上.</p><h2 id="具体例子">具体例子</h2><p><strong>标量对向量求导:</strong></p><p>​ 令<span class="math inline">\(x=[x_1,x_2,x_3]^T\)</span>，<span class="math inline">\(w=[w_1,w_2,w_3]^T\)</span>，<span class="math inline">\(y=w*x+b\)</span></p><p>​ 则偏导数为： <span class="math display">\[\frac{\part y}{\part x}=[\frac{\part y}{\part x_1},\frac{\part y}{\part x_2},\frac{\part y}{\part x_3}]=[w_1,w_2,w_3]\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">w = torch.tensor([<span class="number">4.0</span>,<span class="number">5.0</span>,<span class="number">6.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = <span class="number">10</span></span><br><span class="line">y = torch.dot(x,w)+b</span><br><span class="line">y.backward()</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"><span class="built_in">print</span>(w.grad)</span><br><span class="line"></span><br><span class="line">output:</span><br><span class="line">&lt;&lt;&lt;tensor([<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>])</span><br><span class="line">&lt;&lt;&lt;tensor([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>])</span><br></pre></td></tr></table></figure><p><strong>标量对矩阵求导:</strong></p><p>​ 令$X=$</p><p>​ 第一次操作： <span class="math display">\[Y=X+1=\left[ \begin{matrix}{}    x_{11}+1&amp;       x_{12}+1&amp;       x_{13}+1\\    x_{21}+1&amp;       x_{22}+1&amp;       x_{23}+1\\\end{matrix} \right]\]</span> ​ 第二次操作： <span class="math display">\[Z=\left[ \begin{matrix}{}    z_{11}&amp;     z_{12}&amp;     z_{13}\\    z_{21}&amp;     z_{22}&amp;     z_{23}\\\end{matrix} \right] =\left[ \begin{matrix}{}    \left( y_{11} \right) ^2&amp;       \left( y_{12} \right) ^2&amp;       \left( y_{13} \right) ^2\\    \left( y_{21} \right) ^2&amp;       \left( y_{22} \right) ^2&amp;       \left( y_{23} \right) ^2\\\end{matrix} \right]\]</span> ​ 第三次操作： <span class="math display">\[f=\frac{1}{6}sum(Z)\]</span> ​ 偏导数为： <span class="math display">\[\frac{\part f}{\part x_{ij}}=\frac{1}{6}*2(\frac{\part(x_{ij}+1)^2}{\part x_{ij}})=\frac{1}{3}(x_{ij}+1)\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.autograd</span><br><span class="line"></span><br><span class="line">x = torch.tensor([[<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>],[<span class="number">4.0</span>,<span class="number">5.0</span>,<span class="number">6.0</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = x+<span class="number">1</span></span><br><span class="line">z = y**<span class="number">2</span></span><br><span class="line">f = torch.mean(z)</span><br><span class="line"></span><br><span class="line">f.backward()</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line">ouput:</span><br><span class="line">&lt;&lt;&lt;tensor([[<span class="number">0.6667</span>, <span class="number">1.0000</span>, <span class="number">1.3333</span>],</span><br><span class="line">        [<span class="number">1.6667</span>, <span class="number">2.0000</span>, <span class="number">2.3333</span>]])</span><br></pre></td></tr></table></figure><p><strong>向量/矩阵对向量/矩阵求导：</strong></p><p>​ 在pytorch中一般标量对向量或矩阵用的比较多，因为深度学习中最后的loss是输出一个值为标量，因此向量对矩阵求导需要传入一个梯度，即传入一个<span class="math inline">\(l\)</span>对<span class="math inline">\(f\)</span>的求导得到的梯度。</p><p>​ 令<span class="math inline">\(x=[x_1,x_2,x_3]\)</span>，<span class="math inline">\(y=x*2=[2*x_1,2*x_2,2*x_3]\)</span>，此时对应上面1.3节有，<span class="math inline">\(y=(f_1,f_2,f_3)\)</span>，其中<span class="math inline">\(f_i=2*x_i\)</span>，所以有： <span class="math display">\[\frac{dy}{dx}=\left[ \begin{matrix}    \frac{\partial f_1}{\partial x_1}&amp;\frac{\partial f_1}{\partial x_2}     &amp;       \frac{\partial f_1}{\partial x_3}\\\frac{\partial f_2}{\partial x_1}   &amp;   \frac{\partial f_2}{\partial x_2}   &amp;\frac{\partial f_2}{\partial x_3}      \\    \frac{\partial f_3}{\partial x_1}&amp;  \frac{\partial f_3}{\partial x_2}   &amp;   \frac{\partial f_3}{\partial x_3}   \\\end{matrix} \right] =\left[ \begin{matrix}    2&amp;0     &amp;       0\\0   &amp;   2   &amp;0      \\    0&amp;  0   &amp;2\\\end{matrix} \right]\]</span> ​ 传入：<span class="math inline">\(v\)</span>为<span class="math inline">\(l\)</span>对<span class="math inline">\(f\)</span>的梯度 <span class="math display">\[v=[0.1,1.0,0.0001]\]</span> ​ 例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = x * <span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line">v = torch.tensor([<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">0.0001</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">y.backward(v)</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line">output:</span><br><span class="line">&lt;&lt;&lt;tensor([-<span class="number">0.1656</span>,  <span class="number">1.2321</span>, -<span class="number">3.1254</span>], grad_fn=&lt;MulBackward0&gt;)</span><br><span class="line">&lt;&lt;&lt;tensor([<span class="number">2.0000e-01</span>, <span class="number">2.0000e+00</span>, <span class="number">2.0000e-04</span>])</span><br></pre></td></tr></table></figure><p>​ <strong>注意此处获得的梯度是<span class="math inline">\(l\)</span>对<span class="math inline">\(x\)</span>的梯度，而<span class="math inline">\(l\)</span>是没有显式的，因为只是传入了一个<span class="math inline">\(l\)</span>对<span class="math inline">\(f\)</span>的梯度。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 编程学习 </category>
          
          <category> pytorch学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python基础查漏补缺</title>
      <link href="/2022/09/16/python%E5%9F%BA%E7%A1%80%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/"/>
      <url>/2022/09/16/python%E5%9F%BA%E7%A1%80%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/</url>
      
        <content type="html"><![CDATA[<h3 id="高级特性"><a href="#高级特性" class="headerlink" title="高级特性"></a>高级特性</h3><h4 id="迭代"><a href="#迭代" class="headerlink" title="迭代"></a>迭代</h4><p>如何判断一个对象是可迭代对象呢？</p><p>方法是通过<code>collections.abc</code>模块的<code>Iterable</code>类型判断：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections.abc <span class="keyword">import</span> Iterable</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(<span class="string">&#x27;abc&#x27;</span>, Iterable) <span class="comment"># str是否可迭代</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], Iterable) <span class="comment"># list是否可迭代</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(<span class="number">123</span>, Iterable) <span class="comment"># 整数是否可迭代</span></span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure><p>将<code>list</code>对象转换成可迭代对象，进行对下标运算</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i, value <span class="keyword">in</span> <span class="built_in">enumerate</span>([<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>]):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(i, value)</span><br><span class="line">...</span><br><span class="line"><span class="number">0</span> A</span><br><span class="line"><span class="number">1</span> B</span><br><span class="line"><span class="number">2</span> C</span><br></pre></td></tr></table></figure><p>上面的<code>for</code>循环里，同时引用了两个变量，在Python里是很常见的，比如下面的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> x, y <span class="keyword">in</span> [(<span class="number">1</span>, <span class="number">1</span>), (<span class="number">2</span>, <span class="number">4</span>), (<span class="number">3</span>, <span class="number">9</span>)]:</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(x, y)</span><br><span class="line">...</span><br><span class="line"><span class="number">1</span> <span class="number">1</span></span><br><span class="line"><span class="number">2</span> <span class="number">4</span></span><br><span class="line"><span class="number">3</span> <span class="number">9</span></span><br></pre></td></tr></table></figure><h4 id="列表生成式"><a href="#列表生成式" class="headerlink" title="列表生成式"></a>列表生成式</h4><p>利用列表函数进行生成</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>[x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>)]</span><br><span class="line">[<span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>, <span class="number">25</span>, <span class="number">36</span>, <span class="number">49</span>, <span class="number">64</span>, <span class="number">81</span>, <span class="number">100</span>]</span><br></pre></td></tr></table></figure><p>还可以使用两层循环，可以生成全排列：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>[m + n <span class="keyword">for</span> m <span class="keyword">in</span> <span class="string">&#x27;ABC&#x27;</span> <span class="keyword">for</span> n <span class="keyword">in</span> <span class="string">&#x27;XYZ&#x27;</span>]</span><br><span class="line">[<span class="string">&#x27;AX&#x27;</span>, <span class="string">&#x27;AY&#x27;</span>, <span class="string">&#x27;AZ&#x27;</span>, <span class="string">&#x27;BX&#x27;</span>, <span class="string">&#x27;BY&#x27;</span>, <span class="string">&#x27;BZ&#x27;</span>, <span class="string">&#x27;CX&#x27;</span>, <span class="string">&#x27;CY&#x27;</span>, <span class="string">&#x27;CZ&#x27;</span>]</span><br></pre></td></tr></table></figure><p><code>if</code>和<code>else</code>写法</p><p>正确</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>[x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span>]</span><br><span class="line">[<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">10</span>]</span><br></pre></td></tr></table></figure><p>错误，我们不能在最后的<code>if</code>加上<code>else</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>[x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>]</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span></span><br><span class="line">    [x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>]</span><br><span class="line">                                              ^</span><br><span class="line">SyntaxError: invalid syntax</span><br></pre></td></tr></table></figure><p>在一个列表生成式中，<code>for</code>前面的<code>if ... else</code>是表达式，而<code>for</code>后面的<code>if</code>是过滤条件，不能带<code>else</code></p><p>例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>[x <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span> <span class="keyword">else</span> -x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>)]</span><br><span class="line">[-<span class="number">1</span>, <span class="number">2</span>, -<span class="number">3</span>, <span class="number">4</span>, -<span class="number">5</span>, <span class="number">6</span>, -<span class="number">7</span>, <span class="number">8</span>, -<span class="number">9</span>, <span class="number">10</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#等价于</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">11</span>):</span><br><span class="line">    <span class="keyword">if</span> x % <span class="number">2</span>==<span class="number">0</span>:</span><br><span class="line">        x</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        -x</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>L1 = [<span class="string">&#x27;Hello&#x27;</span>, <span class="string">&#x27;World&#x27;</span>, <span class="number">18</span>, <span class="string">&#x27;Apple&#x27;</span>, <span class="literal">None</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[s.lower() <span class="keyword">if</span> <span class="built_in">isinstance</span>(s, <span class="built_in">str</span>) <span class="keyword">else</span> s <span class="keyword">for</span> s <span class="keyword">in</span> L1 <span class="keyword">if</span> s!=<span class="literal">None</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#等价于</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> L1:</span><br><span class="line">    <span class="keyword">if</span> s!=<span class="literal">None</span>:<span class="comment"># 过滤条件</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(s, <span class="built_in">str</span>):</span><br><span class="line">            s.lower()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            s</span><br></pre></td></tr></table></figure><h4 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h4><p>列表生成器的缺陷：<code>将数据全部生成浪费内存</code></p><p>通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。而且，创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。</p><p>如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器:<code>generator</code>。</p><p>方法一：将列表生成式的[]改成()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>L = [x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>L</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>, <span class="number">25</span>, <span class="number">36</span>, <span class="number">49</span>, <span class="number">64</span>, <span class="number">81</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>g = (x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>g</span><br><span class="line">&lt;generator <span class="built_in">object</span> &lt;genexpr&gt; at <span class="number">0x1022ef630</span>&gt;</span><br></pre></td></tr></table></figure><p>通过<code>next()</code>函数获得generator的下一个返回值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(g)</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(g)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(g)</span><br><span class="line"><span class="number">4</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(g)</span><br><span class="line"><span class="number">9</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(g)</span><br><span class="line"><span class="number">16</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(g)</span><br><span class="line"><span class="number">25</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(g)</span><br><span class="line"><span class="number">36</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(g)</span><br><span class="line"><span class="number">49</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(g)</span><br><span class="line"><span class="number">64</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(g)</span><br><span class="line"><span class="number">81</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(g)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">StopIteration</span><br></pre></td></tr></table></figure><p>generator保存的是算法，每次调用<code>next(g)</code>，就计算出<code>g</code>的下一个元素的值，直到计算到最后一个元素，没有更多的元素时，抛出<code>StopIteration</code>的错误。</p><p>可以使用<code>for</code>进行调用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>g = (x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> n <span class="keyword">in</span> g:</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(n)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">4</span></span><br><span class="line"><span class="number">9</span></span><br><span class="line"><span class="number">16</span></span><br><span class="line"><span class="number">25</span></span><br><span class="line"><span class="number">36</span></span><br><span class="line"><span class="number">49</span></span><br><span class="line"><span class="number">64</span></span><br><span class="line"><span class="number">81</span></span><br></pre></td></tr></table></figure><p>另一种写法：<code>yield</code>关键字</p><p>考虑斐波拉契数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fib</span>(<span class="params"><span class="built_in">max</span></span>):</span><br><span class="line">    n, a, b = <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> n &lt; <span class="built_in">max</span>:</span><br><span class="line">        <span class="built_in">print</span>(b)</span><br><span class="line">        a, b = b, a + b</span><br><span class="line">        n = n + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;done&#x27;</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fib(<span class="number">6</span>)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="number">8</span></span><br><span class="line"><span class="string">&#x27;done&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加入yield关键字</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fib</span>(<span class="params"><span class="built_in">max</span></span>):</span><br><span class="line">    n, a, b = <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> n &lt; <span class="built_in">max</span>:</span><br><span class="line">        <span class="keyword">yield</span> b</span><br><span class="line">        a, b = b, a + b</span><br><span class="line">        n = n + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;done&#x27;</span></span><br></pre></td></tr></table></figure><p>如果一个函数定义中包含<code>yield</code>关键字，那么这个函数就不再是一个普通函数，而是一个generator函数，调用一个generator函数将返回一个generator</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>f = fib(<span class="number">6</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f</span><br><span class="line">&lt;generator <span class="built_in">object</span> fib at <span class="number">0x104feaaa0</span>&gt;</span><br></pre></td></tr></table></figure><p>举个简单的例子，定义一个generator函数，依次返回数字1，3，5：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">odd</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;step 1&#x27;</span>)</span><br><span class="line">    <span class="keyword">yield</span> <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;step 2&#x27;</span>)</span><br><span class="line">    <span class="keyword">yield</span>(<span class="number">3</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;step 3&#x27;</span>)</span><br><span class="line">    <span class="keyword">yield</span>(<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>o = odd()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(o)  <span class="comment"># 指向yield 1</span></span><br><span class="line">step <span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(o)  <span class="comment"># 指向yield 3</span></span><br><span class="line">step <span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(o)  <span class="comment"># 指向yield 5</span></span><br><span class="line">step <span class="number">3</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(o)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">StopIteration</span><br></pre></td></tr></table></figure><p>每次调用<code>odd</code>会重新生成一个<code>generator</code>对象</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(odd())</span><br><span class="line">step <span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(odd())</span><br><span class="line">step <span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(odd())</span><br><span class="line">step <span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure><p>同样的，把函数改成generator函数后，我们基本上从来不会用<code>next()</code>来获取下一个返回值，而是直接使用<code>for</code>循环来迭代：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> n <span class="keyword">in</span> fib(<span class="number">6</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(n)</span><br><span class="line">...</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure><p>但是用<code>for</code>循环调用generator时，发现拿不到generator的<code>return</code>语句的返回值。如果想要拿到返回值，必须捕获<code>StopIteration</code>错误，返回值包含在<code>StopIteration</code>的<code>value</code>中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>g = fib(<span class="number">6</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">try</span>:</span><br><span class="line"><span class="meta">... </span>        x = <span class="built_in">next</span>(g)</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">print</span>(<span class="string">&#x27;g:&#x27;</span>, x)</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">except</span> StopIteration <span class="keyword">as</span> e:</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">print</span>(<span class="string">&#x27;Generator return value:&#x27;</span>, e.value)</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">break</span></span><br><span class="line">...</span><br><span class="line">g: <span class="number">1</span></span><br><span class="line">g: <span class="number">1</span></span><br><span class="line">g: <span class="number">2</span></span><br><span class="line">g: <span class="number">3</span></span><br><span class="line">g: <span class="number">5</span></span><br><span class="line">g: <span class="number">8</span></span><br><span class="line">Generator <span class="keyword">return</span> value: done</span><br></pre></td></tr></table></figure><p>练习：生成杨辉三角</p><p><a href="http://baike.baidu.com/view/7804.htm">杨辉三角</a>定义如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">          1</span><br><span class="line">         / \</span><br><span class="line">        1   1</span><br><span class="line">       / \ / \</span><br><span class="line">      1   2   1</span><br><span class="line">     / \ / \ / \</span><br><span class="line">    1   3   3   1</span><br><span class="line">   / \ / \ / \ / \</span><br><span class="line">  1   4   6   4   1</span><br><span class="line"> / \ / \ / \ / \ / \</span><br><span class="line">1   5   10  10  5   1</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">triangles</span>():</span><br><span class="line">    count=<span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">        <span class="keyword">if</span> count==<span class="number">1</span>:</span><br><span class="line">            L=[<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">yield</span> L<span class="comment"># 保留L</span></span><br><span class="line">        <span class="keyword">if</span> count==<span class="number">2</span>:</span><br><span class="line">            L=[<span class="number">1</span>,<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">yield</span> L<span class="comment"># 保留L</span></span><br><span class="line">        <span class="keyword">if</span> count&gt;<span class="number">2</span>:</span><br><span class="line">            <span class="comment"># 列表生成</span></span><br><span class="line">            L=[<span class="built_in">sum</span>(L[i:i+<span class="number">2</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(L)) <span class="keyword">if</span> i+<span class="number">1</span>&lt;<span class="built_in">len</span>(L)]</span><br><span class="line">            L.insert(<span class="number">0</span>,<span class="number">1</span>)<span class="comment"># 在列表头插入元素</span></span><br><span class="line">            L.append(<span class="number">1</span>)<span class="comment"># 在列表尾插入元素</span></span><br><span class="line">            <span class="keyword">yield</span> L<span class="comment"># 保留L</span></span><br><span class="line">        count=count+<span class="number">1</span></span><br><span class="line">n = <span class="number">0</span></span><br><span class="line">results = []</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> triangles():<span class="comment"># 调用生成器</span></span><br><span class="line">    results.append(t)</span><br><span class="line">    n = n + <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">10</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> results:</span><br><span class="line">    <span class="built_in">print</span>(t)</span><br><span class="line"><span class="keyword">if</span> results == [</span><br><span class="line">    [<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">5</span>, <span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>, <span class="number">6</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">15</span>, <span class="number">6</span>, <span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>, <span class="number">7</span>, <span class="number">21</span>, <span class="number">35</span>, <span class="number">35</span>, <span class="number">21</span>, <span class="number">7</span>, <span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>, <span class="number">8</span>, <span class="number">28</span>, <span class="number">56</span>, <span class="number">70</span>, <span class="number">56</span>, <span class="number">28</span>, <span class="number">8</span>, <span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>, <span class="number">9</span>, <span class="number">36</span>, <span class="number">84</span>, <span class="number">126</span>, <span class="number">126</span>, <span class="number">84</span>, <span class="number">36</span>, <span class="number">9</span>, <span class="number">1</span>]</span><br><span class="line">]:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;测试通过!&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;测试失败!&#x27;</span>)</span><br></pre></td></tr></table></figure><h4 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h4><p>我们已经知道，可以直接作用于<code>for</code>循环的数据类型有以下几种：</p><p>一类是集合数据类型，如<code>list</code>、<code>tuple</code>、<code>dict</code>、<code>set</code>、<code>str</code>等；</p><p>一类是<code>generator</code>，包括生成器和带<code>yield</code>的generator function。</p><p>这些可以直接作用于<code>for</code>循环的对象统称为可迭代对象：<code>Iterable</code>。</p><p>可以被<code>next()</code>函数调用并不断返回下一个值的对象称为迭代器：<code>Iterator</code>。</p><p>生成器都是<code>Iterator</code>对象，但<code>list</code>、<code>dict</code>、<code>str</code>虽然是<code>Iterable</code>，却不是<code>Iterator</code>。</p><p>把<code>list</code>、<code>dict</code>、<code>str</code>等<code>Iterable</code>变成<code>Iterator</code>可以使用<code>iter()</code>函数：</p><p>为什么<code>list</code>、<code>dict</code>、<code>str</code>等数据类型不是<code>Iterator</code>？</p><p>这是因为Python的<code>Iterator</code>对象表示的是一个数据流，Iterator对象可以被<code>next()</code>函数调用并不断返回下一个数据，直到没有数据时抛出<code>StopIteration</code>错误。可以把这个数据流看做是一个有序序列，但我们却不能提前知道序列的长度，只能不断通过<code>next()</code>函数实现按需计算下一个数据，所以<code>Iterator</code>的计算是惰性的，只有在需要返回下一个数据时它才会计算。</p><p><strong>小结</strong></p><p>凡是可作用于<code>for</code>循环的对象都是<code>Iterable</code>类型；</p><p>凡是可作用于<code>next()</code>函数的对象都是<code>Iterator</code>类型，它们表示一个惰性计算的序列；</p><p>集合数据类型如<code>list</code>、<code>dict</code>、<code>str</code>等是<code>Iterable</code>但不是<code>Iterator</code>，不过可以通过<code>iter()</code>函数获得一个<code>Iterator</code>对象。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 等价于</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 首先获得Iterator对象:</span></span><br><span class="line">it = <span class="built_in">iter</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"><span class="comment"># 循环:</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 获得下一个值:</span></span><br><span class="line">        x = <span class="built_in">next</span>(it)</span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="comment"># 遇到StopIteration就退出循环</span></span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><h3 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h3><p>函数式编程的一个特点就是，允许把函数本身作为参数传入另一个函数，还允许返回一个函数！</p><h4 id="高阶函数"><a href="#高阶函数" class="headerlink" title="高阶函数"></a>高阶函数</h4><h5 id="map-reduce"><a href="#map-reduce" class="headerlink" title="map/reduce"></a>map/reduce</h5><p><strong>map</strong></p><p><code>map()</code>函数接收两个参数，一个是函数，一个是<code>Iterable</code>，<code>map</code>将传入的函数依次作用到序列的每个元素，并把结果作为新的<code>Iterator</code>返回。</p><p>举例说明，比如我们有一个函数f(x)=x2，要把这个函数作用在一个list <code>[1, 2, 3, 4, 5, 6, 7, 8, 9]</code>上，就可以用<code>map()</code>实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> x * x</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = <span class="built_in">map</span>(f, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(r)</span><br><span class="line">[<span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>, <span class="number">25</span>, <span class="number">36</span>, <span class="number">49</span>, <span class="number">64</span>, <span class="number">81</span>]</span><br></pre></td></tr></table></figure><p><code>map()</code>传入的第一个参数是<code>f</code>，即函数对象本身。由于结果<code>r</code>是一个<code>Iterator</code>，<code>Iterator</code>是惰性序列，因此通过<code>list()</code>函数让它把整个序列都计算出来并返回一个list。</p><p>你可能会想，不需要<code>map()</code>函数，写一个循环，也可以计算出结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">L = []</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]:</span><br><span class="line">    L.append(f(n))</span><br><span class="line"><span class="built_in">print</span>(L)</span><br></pre></td></tr></table></figure><p>的确可以，但是，从上面的循环代码，能一眼看明白“把f(x)作用在list的每一个元素并把结果生成一个新的list”吗？</p><p>所以，<code>map()</code>作为高阶函数，事实上它把运算规则抽象了，因此，我们不但可以计算简单的$f(x)=x^2$，还可以计算任意复杂的函数，比如，把这个list所有数字转为字符串：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">str</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]))</span><br><span class="line">[<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;4&#x27;</span>, <span class="string">&#x27;5&#x27;</span>, <span class="string">&#x27;6&#x27;</span>, <span class="string">&#x27;7&#x27;</span>, <span class="string">&#x27;8&#x27;</span>, <span class="string">&#x27;9&#x27;</span>]</span><br></pre></td></tr></table></figure><p><strong>reduce</strong></p><p>再看<code>reduce</code>的用法。<code>reduce</code>把一个函数作用在一个序列<code>[x1, x2, x3, ...]</code>上，这个函数必须接收两个参数，<code>reduce</code>把结果继续和序列的下一个元素做累积计算，其效果就是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4)</span><br></pre></td></tr></table></figure><p>例：将序列<code>[1, 3, 5, 7, 9]</code>变换成整数<code>13579</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">fn</span>(<span class="params">x, y</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> x * <span class="number">10</span> + y</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reduce(fn, [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>])</span><br><span class="line"><span class="number">13579</span></span><br></pre></td></tr></table></figure><p>例：将字符串转为整数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">fn</span>(<span class="params">x, y</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> x * <span class="number">10</span> + y</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">char2num</span>(<span class="params">s</span>):</span><br><span class="line"><span class="meta">... </span>    digits = &#123;<span class="string">&#x27;0&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;1&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;2&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;3&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;4&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;5&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;6&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;7&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;8&#x27;</span>: <span class="number">8</span>, <span class="string">&#x27;9&#x27;</span>: <span class="number">9</span>&#125;</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> digits[s]</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reduce(fn, <span class="built_in">map</span>(char2num, <span class="string">&#x27;13579&#x27;</span>))</span><br><span class="line"><span class="number">13579</span></span><br></pre></td></tr></table></figure><p>整理成一个<code>str2int</code>的函数就是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"></span><br><span class="line">DIGITS = &#123;<span class="string">&#x27;0&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;1&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;2&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;3&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;4&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;5&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;6&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;7&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;8&#x27;</span>: <span class="number">8</span>, <span class="string">&#x27;9&#x27;</span>: <span class="number">9</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">str2int</span>(<span class="params">s</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fn</span>(<span class="params">x, y</span>):</span><br><span class="line">        <span class="keyword">return</span> x * <span class="number">10</span> + y</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">char2num</span>(<span class="params">s</span>):</span><br><span class="line">        <span class="keyword">return</span> DIGITS[s]</span><br><span class="line">    <span class="keyword">return</span> reduce(fn, <span class="built_in">map</span>(char2num, s))</span><br></pre></td></tr></table></figure><p>还可以用lambda函数进一步简化成：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"></span><br><span class="line">DIGITS = &#123;<span class="string">&#x27;0&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;1&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;2&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;3&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;4&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;5&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;6&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;7&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;8&#x27;</span>: <span class="number">8</span>, <span class="string">&#x27;9&#x27;</span>: <span class="number">9</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">char2num</span>(<span class="params">s</span>):</span><br><span class="line">    <span class="keyword">return</span> DIGITS[s]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">str2int</span>(<span class="params">s</span>):</span><br><span class="line">    <span class="keyword">return</span> reduce(<span class="keyword">lambda</span> x, y: x * <span class="number">10</span> + y, <span class="built_in">map</span>(char2num, s))</span><br></pre></td></tr></table></figure><h5 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h5><p>Python内建的<code>filter()</code>函数用于过滤序列。</p><p>和<code>map()</code>类似，<code>filter()</code>也接收一个函数和一个序列。和<code>map()</code>不同的是，<code>filter()</code>把传入的函数依次作用于每个元素，然后根据返回值是<code>True</code>还是<code>False</code>决定保留还是丢弃该元素。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">is_odd</span>(<span class="params">n</span>):</span><br><span class="line">    <span class="keyword">return</span> n % <span class="number">2</span> == <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">list</span>(<span class="built_in">filter</span>(is_odd, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">15</span>]))</span><br><span class="line"><span class="comment"># 结果: [1, 5, 9, 15]</span></span><br></pre></td></tr></table></figure><p>例：将一个序列中的空字符串删除</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">not_empty</span>(<span class="params">s</span>):</span><br><span class="line">    <span class="keyword">return</span> s <span class="keyword">and</span> s.strip()</span><br><span class="line"></span><br><span class="line"><span class="built_in">list</span>(<span class="built_in">filter</span>(not_empty, [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="literal">None</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;  &#x27;</span>]))</span><br><span class="line"><span class="comment"># 结果: [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;]</span></span><br></pre></td></tr></table></figure><p>注意：<code>filter()</code>函数返回的是一个<code>Iterator</code>，也就是一个惰性序列，所以要强迫<code>filter()</code>完成计算结果，需要用<code>list()</code>函数获得所有结果并返回list。</p><p>例：求素数</p><p>计算<a href="http://baike.baidu.com/view/10626.htm">素数</a>的一个方法是<a href="http://baike.baidu.com/view/3784258.htm">埃氏筛法</a>，它的算法理解起来非常简单：</p><p>首先，列出从<code>2</code>开始的所有自然数，构造一个序列：</p><p>2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, …</p><p>取序列的第一个数<code>2</code>，它一定是素数，然后用<code>2</code>把序列的<code>2</code>的倍数筛掉：</p><p>3, <del>4</del>, 5, <del>6</del>, 7, <del>8</del>, 9, <del>10</del>, 11, <del>12</del>, 13, <del>14</del>, 15, <del>16</del>, 17, <del>18</del>, 19, <del>20</del>, …</p><p>取新序列的第一个数<code>3</code>，它一定是素数，然后用<code>3</code>把序列的<code>3</code>的倍数筛掉：</p><p>5, <del>6</del>, 7, <del>8</del>, <del>9</del>, <del>10</del>, 11, <del>12</del>, 13, <del>14</del>, <del>15</del>, <del>16</del>, 17, <del>18</del>, 19, <del>20</del>, …</p><p>取新序列的第一个数<code>5</code>，然后用<code>5</code>把序列的<code>5</code>的倍数筛掉：</p><p>7, <del>8</del>, <del>9</del>, <del>10</del>, 11, <del>12</del>, 13, <del>14</del>, <del>15</del>, <del>16</del>, 17, <del>18</del>, 19, <del>20</del>, …</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义生成器生成序列</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_odd_iter</span>():</span><br><span class="line">    n = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        n = n + <span class="number">2</span></span><br><span class="line">        <span class="keyword">yield</span> n</span><br><span class="line"><span class="comment"># 筛选函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_not_divisible</span>(<span class="params">n</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">lambda</span> x: x % n &gt; <span class="number">0</span></span><br><span class="line"><span class="comment"># 定义一个生成器筛选下一个素数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">primes</span>():</span><br><span class="line">    <span class="keyword">yield</span> <span class="number">2</span></span><br><span class="line">    it = _odd_iter() <span class="comment"># 初始序列</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        n = <span class="built_in">next</span>(it) <span class="comment"># 返回序列的第一个数</span></span><br><span class="line">        <span class="keyword">yield</span> n</span><br><span class="line">        it = <span class="built_in">filter</span>(_not_divisible(n), it) <span class="comment"># 构造新序列</span></span><br></pre></td></tr></table></figure><p><code>filter(_not_divisible(n), it)</code>对n在it生成器中进行_not_divisible(n)判断是否正确，若正确则不舍弃</p><h4 id="返回函数-闭包"><a href="#返回函数-闭包" class="headerlink" title="返回函数/闭包"></a>返回函数/闭包</h4><p>高阶函数除了可以接受函数作为参数外，还可以把函数作为结果值返回</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lazy_sum</span>(<span class="params">*args</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sum</span>():</span><br><span class="line">        ax = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> args:</span><br><span class="line">            ax = ax + n</span><br><span class="line">        <span class="keyword">return</span> ax</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f = lazy_sum(<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f</span><br><span class="line">&lt;function lazy_sum.&lt;<span class="built_in">locals</span>&gt;.<span class="built_in">sum</span> at <span class="number">0x101c6ed90</span>&gt;</span><br></pre></td></tr></table></figure><p>​       </p><h3 id="面向对象编程"><a href="#面向对象编程" class="headerlink" title="面向对象编程"></a>面向对象编程</h3><h4 id="类和实例"><a href="#类和实例" class="headerlink" title="类和实例"></a>类和实例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="comment"># 给Student绑定一个属性</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart.name = <span class="string">&#x27;Bart Simpson&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart.name</span><br><span class="line"><span class="string">&#x27;Bart Simpson&#x27;</span></span><br><span class="line"><span class="comment"># __init__方法创建实例</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name, score</span>):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.score = score</span><br></pre></td></tr></table></figure><h4 id="访问限制"><a href="#访问限制" class="headerlink" title="访问限制"></a>访问限制</h4><p>实例的变量名如果以<code>__</code>开头，就变成了一个私有变量（private），只有内部可以访问，外部不能访问。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name, score</span>):</span><br><span class="line">        self.__name = name</span><br><span class="line">        self.__score = score</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">print_score</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;%s: %s&#x27;</span> % (self.__name, self.__score))</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 利用定义一个函数进行获得属性</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_name</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.__name</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_score</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.__score</span><br></pre></td></tr></table></figure><h4 id="获取对象信息"><a href="#获取对象信息" class="headerlink" title="获取对象信息"></a>获取对象信息</h4><p>如果要获得一个对象的所有属性和方法，可以使用<code>dir()</code>函数，它返回一个包含字符串的list，比如，获得一个str对象的所有属性和方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">dir</span>(<span class="string">&#x27;ABC&#x27;</span>)</span><br><span class="line">[<span class="string">&#x27;__add__&#x27;</span>, <span class="string">&#x27;__class__&#x27;</span>,..., <span class="string">&#x27;__subclasshook__&#x27;</span>, <span class="string">&#x27;capitalize&#x27;</span>, <span class="string">&#x27;casefold&#x27;</span>,..., <span class="string">&#x27;zfill&#x27;</span>]</span><br></pre></td></tr></table></figure><p>其中带有下横线的是方法，其他的为属性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(<span class="string">&#x27;ABC&#x27;</span>)</span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&#x27;ABC&#x27;</span>.__len__()</span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure><p>我们自己写的类，如果也想用<code>len(myObj)</code>的话，就自己写一个<code>__len__()</code>方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">MyDog</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> <span class="number">100</span></span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dog = MyDog()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(dog)</span><br><span class="line"><span class="number">100</span></span><br></pre></td></tr></table></figure><h3 id="面对对象高级编程"><a href="#面对对象高级编程" class="headerlink" title="面对对象高级编程"></a>面对对象高级编程</h3><h4 id="slots"><a href="#slots" class="headerlink" title="__slots__"></a>__slots__</h4><p>利用MethodType方法给实例绑定一个方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">set_age</span>(<span class="params">self, age</span>): <span class="comment"># 定义一个函数作为实例方法</span></span><br><span class="line"><span class="meta">... </span>    self.age = age</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> types <span class="keyword">import</span> MethodType</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.set_age = MethodType(set_age, s) <span class="comment"># 给实例绑定一个方法</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.set_age(<span class="number">25</span>) <span class="comment"># 调用实例方法</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.age <span class="comment"># 测试结果</span></span><br><span class="line"><span class="number">25</span></span><br></pre></td></tr></table></figure><p>给class绑定方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">set_score</span>(<span class="params">self, score</span>):</span><br><span class="line"><span class="meta">... </span>    self.score = score</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Student.set_score = set_score</span><br></pre></td></tr></table></figure><p><strong>使用__slots__</strong>可以给实例限制绑定的属性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    __slots__ = (<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;age&#x27;</span>) <span class="comment"># 用tuple定义允许绑定的属性名称</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s = Student() <span class="comment"># 创建新的实例</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.name = <span class="string">&#x27;Michael&#x27;</span> <span class="comment"># 绑定属性&#x27;name&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.age = <span class="number">25</span> <span class="comment"># 绑定属性&#x27;age&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.score = <span class="number">99</span> <span class="comment"># 绑定属性&#x27;score&#x27;</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">AttributeError: <span class="string">&#x27;Student&#x27;</span> <span class="built_in">object</span> has no attribute <span class="string">&#x27;score&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="定制类"><a href="#定制类" class="headerlink" title="定制类"></a>定制类</h4><p>看到类似<code>__slots__</code>这种形如<code>__xxx__</code>的变量或者函数名就要注意，这些在Python中是有特殊用途的。</p><p><code>__slots__</code>我们已经知道怎么用了，<code>__len__()</code>方法我们也知道是为了能让class作用于<code>len()</code>函数。</p><p><strong>__str__</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name</span>):</span><br><span class="line"><span class="meta">... </span>        self.name = name</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(Student(<span class="string">&#x27;Michael&#x27;</span>))</span><br><span class="line">&lt;__main__.Student <span class="built_in">object</span> at <span class="number">0x109afb190</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name</span>):</span><br><span class="line"><span class="meta">... </span>        self.name = name</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> <span class="string">&#x27;Student object (name: %s)&#x27;</span> % self.name</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(Student(<span class="string">&#x27;Michael&#x27;</span>))</span><br><span class="line">Student <span class="built_in">object</span> (name: Michael)</span><br></pre></td></tr></table></figure><p><strong>__iter__</strong></p><p>如果一个类想被用于<code>for ... in</code>循环，类似list或tuple那样，就必须实现一个<code>__iter__()</code>方法，该方法返回一个迭代对象，然后，Python的for循环就会不断调用该迭代对象的<code>__next__()</code>方法拿到循环的下一个值，直到遇到<code>StopIteration</code>错误时退出循环。</p><p>我们以斐波那契数列为例，写一个Fib类，可以作用于for循环：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Fib</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.a, self.b = <span class="number">0</span>, <span class="number">1</span> <span class="comment"># 初始化两个计数器a，b</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self <span class="comment"># 实例本身就是迭代对象，故返回自己</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__next__</span>(<span class="params">self</span>):</span><br><span class="line">        self.a, self.b = self.b, self.a + self.b <span class="comment"># 计算下一个值</span></span><br><span class="line">        <span class="keyword">if</span> self.a &gt; <span class="number">100000</span>: <span class="comment"># 退出循环的条件</span></span><br><span class="line">            <span class="keyword">raise</span> StopIteration()</span><br><span class="line">        <span class="keyword">return</span> self.a <span class="comment"># 返回下一个值</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> n <span class="keyword">in</span> Fib():</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(n)</span><br><span class="line">...</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line">...</span><br><span class="line"><span class="number">46368</span></span><br><span class="line"><span class="number">75025</span></span><br></pre></td></tr></table></figure><p><strong>__getitem__</strong></p><p>Fib实例虽然能作用于for循环，看起来和list有点像，但是，把它当成list来使用还是不行，比如，取第5个元素：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>Fib()[<span class="number">5</span>]</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">TypeError: <span class="string">&#x27;Fib&#x27;</span> <span class="built_in">object</span> does <span class="keyword">not</span> support indexing</span><br></pre></td></tr></table></figure><p>要表现得像list那样按照下标取出元素，需要实现<code>__getitem__()</code>方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Fib</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, n</span>):</span><br><span class="line">        a, b = <span class="number">1</span>, <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            a, b = b, a + b</span><br><span class="line">        <span class="keyword">return</span> a</span><br></pre></td></tr></table></figure><p>现在，就可以按下标访问数列的任意一项了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>f = Fib()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f[<span class="number">0</span>]</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f[<span class="number">1</span>]</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f[<span class="number">2</span>]</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f[<span class="number">3</span>]</span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f[<span class="number">10</span>]</span><br><span class="line"><span class="number">89</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f[<span class="number">100</span>]</span><br><span class="line"><span class="number">573147844013817084101</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 编程学习 </category>
          
          <category> python学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch从0构建线性回归模型</title>
      <link href="/2022/09/16/pytorch%E4%BB%8E0%E6%9E%84%E5%BB%BA%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/"/>
      <url>/2022/09/16/pytorch%E4%BB%8E0%E6%9E%84%E5%BB%BA%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<p><em>参考：《动手学深度学习》——李沐</em></p><h4 id="模型原理">模型原理</h4><p>模型定义：(以二维变量为例) <span class="math display">\[\hat{y}=w_1x_1+w_2x_2+b\]</span> ​ 构建的模型得到的<span class="math inline">\(\hat{y}\)</span>是对真实数据<span class="math inline">\(y\)</span>的估计，假设采集的样本数为<span class="math inline">\(n\)</span>，索引为<span class="math inline">\(i\)</span>的样本特征为<span class="math inline">\(x_1^{(i)}\)</span>和<span class="math inline">\(x_2^{(i)}\)</span>，标签为<span class="math inline">\(y^{(i)}\)</span>则有： <span class="math display">\[\hat{y}^{(i)}=w_1x_1^{(i)}+w_2x_2^{(i)}+b\]</span> 定义损失函数：平方误差 <span class="math display">\[l(w_1,w_2,b)=\frac{1}{n}\sum_{i=1}^{n}{l^{(i)}(w_1,w_2,b)}=\frac{1}{n}\sum_{i=1}^{n}{(w_1x_1^{(i)}+w_2x_2^{(i)}+b-y^{(i)})^2}\]</span> ​ 在模型训练中，我们希望找出⼀组模型参数，记为<span class="math inline">\(w_1^*\)</span>，<span class="math inline">\(w_2^*\)</span>，<span class="math inline">\(b^*\)</span>来使训练样本平均损失最小： <span class="math display">\[w_1^*,w_2^*,b=\underset{w_1,w_2,b}{arg\min} l\left( w_1,w_2,b \right)\]</span> 如上述公式可知，通常，<strong>我们用训练数据集中所有样本误差的平均来衡量模型预测的质量</strong></p><p>​ 但对于大量的数据时，采用所有样本往往使得计算量变大。因此将采用小批量随机梯度下降法(BGD)。</p><h4 id="优化方法">优化方法</h4><p>​ 此处需要一定的凸优化基础，可以参考《convex Optimization》—Boyd and L. Vandenberghe</p><h5 id="梯度下降法批量梯度下降法">梯度下降法(批量梯度下降法)</h5><p>​ 我们考虑如下优化目标。 <span class="math display">\[w^*=\underset{w}{arg\min} f(w,x)\]</span> ​ 其中<span class="math inline">\(x\)</span>为给定的数据，其中<span class="math inline">\(f\)</span>可以为任意损失函数。</p><p>​ 因此由梯度下降法可以得到，下一个迭代点为： <span class="math display">\[w_{n+1}=w_n-\alpha\frac{\partial f(w,x)}{\partial w}\]</span> 可以看出，<strong>此处用了所有的数据</strong>，由于<span class="math inline">\(\hat{y}\)</span>可以改写为<span class="math inline">\(\hat{y}=[x_1,x_2,1]*[w_1,w_2,b]^T=x*w^T\)</span>，其中<span class="math inline">\(w=[w_1,w_2,b]\)</span>，所以我们将考虑优化函数：(此处<span class="math inline">\(\frac{1}{2}\)</span>只是为了最终求解的梯度较为好看) <span class="math display">\[w^*=\underset{w}{arg\min}\frac{\partial f(w,x)}{\partial w}=\underset{w}{arg\min}\frac{1}{n}\sum_{i=1}^{n}{\frac{1}{2}(x^{(i)}*w^T-y^{(i)})^2}\]</span> ​ 可以看出此问题是一个凸问题，存在全局最优解，采用梯度下降法是可以得到最优解的，求梯度可得： <span class="math display">\[\frac{\partial f(w,x)}{\partial w}=\frac{\partial \frac{1}{n}\sum_{i=1}^{n}{\frac{1}{2}(x^{(i)}*w^T-y^{(i)})^2}}{\partial w}=\frac{1}{n}\sum_{i=1}^{n}x^{(i)}(x^{(i)}*w^T-y^{(i)})\]</span> ​ 可以看出，上述的下降梯度用上了所有的数据，此方法存在的缺点则是：<strong>计算量大</strong>。存在的优点则是：相比于SGD和BGD<strong>下降速度较快</strong>。</p><h5 id="随机梯度下降法sgd">随机梯度下降法(SGD)</h5><p><strong>算法原理：</strong>（用随机一个梯度近似全体梯度）</p><p>​ 随机梯度下降法则是随机选取一个样本，进行梯度计算，进行参数更新。</p><p>​ 即将上述<span class="math inline">\(\frac{\partial f(w,x)}{\partial w}\)</span>改为：只用一个样本进行计算梯度 <span class="math display">\[\frac{\partial f(w,x)}{\partial w}=x^{(i)}(x^{(i)}*w^T-y^{(i)})\]</span> <strong>收敛性</strong>：(我还没理解透，凸优化和概率论之间的联系还没搞清楚，听说是依期望收敛)</p><p>​ <em>参考：<a href="https://zhuanlan.zhihu.com/p/277709879">浅谈随机梯度下降&amp;小批量梯度下降 - 知乎 (zhihu.com)</a></em></p><p>​ 假设我们样本量为<span class="math inline">\(n\)</span>，则优化函数可以写出： <span class="math display">\[w^*=\underset{w}{arg\min} f(w,x)=\underset{w}{arg\min} \frac{1}{n}(f_1(w,x^{(1)})+f_2(w,x^{(2)})+\cdots+f_n(w,x^{(n)}))\]</span> ​ 其中<span class="math inline">\(f\)</span>为损失函数，此处有点滥用符号，但此式子不难理解，即<strong>对所有的损失加起来的最终值进行求最小</strong>。</p><p>​ 例如：<span class="math inline">\(f\)</span>是平方误差损失即<span class="math inline">\(f=\frac{1}{n}\sum_{i=1}^{n}{\frac{1}{2}(x^{(i)}*w-y^{(i)})^2}\)</span>，则<span class="math inline">\(f_i={\frac{1}{2}(x^{(i)}*w-y^{(i)})^2}\)</span>。</p><p>​ 则有： <span class="math display">\[\frac{\partial f(w,x)}{\partial w}=\frac{1}{n}(\frac{\partial f_1(w,x^{(1)})}{\partial w}+\frac{\partial f_2(w,x^{(2)})}{\partial w}+\cdots+\frac{\partial f_n(w,x^{(n)})}{\partial w})\]</span> ​ 随机梯度下降法则随机选取一个： <span class="math display">\[\frac{\partial f_i(w,x^{(i)})}{\partial w}\]</span> ​ 代替<span class="math inline">\(\frac{\partial f(w,x)}{\partial w}\)</span>进行参数更新。</p><p><strong>优缺点：</strong></p><p>​ 优点：计算量小。</p><p>​ 缺点：参数更新慢。</p><h5 id="小批量随机梯度下降法bgd">小批量随机梯度下降法(BGD)</h5><p><strong>算法原理：</strong>是随机梯度缺点的改进，优点的牺牲。利用小批量样本进行梯度更新。</p><p>​ 小批量随机梯度下降法则是随机选取小批量的样本，进行梯度计算，进行参数更新。</p><p>​ 即将上述<span class="math inline">\(\frac{\partial f(w,x)}{\partial w}\)</span>改为：用小批量样本进行计算梯度。 <span class="math display">\[\frac{\partial f(w,x)}{\partial w}=\frac{1}{|\mathcal{B}|}\sum_{i\in \mathcal{B}}x^{(i)}(x^{(i)}*w-y^{(i)})\]</span> <strong>收敛性</strong>：和随机梯度下降原理一样。</p><p><strong>优缺点</strong>：是梯度下降和随机梯度下降的中和。</p><h4 id="代码实现">代码实现</h4><p>先上代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入库</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> IPython <span class="keyword">import</span> display</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="comment"># 创建数据</span></span><br><span class="line">num_inputs = <span class="number">2</span></span><br><span class="line">num_examples = <span class="number">1000</span></span><br><span class="line">true_w = [<span class="number">2</span>, -<span class="number">3.4</span>]<span class="comment"># 给定数据权重</span></span><br><span class="line">true_b = <span class="number">4.2</span><span class="comment"># 给定参数b</span></span><br><span class="line">features = torch.randn(num_examples,num_inputs</span><br><span class="line">                       ,dtype=torch.float32)<span class="comment"># 利用randn创建随机数据</span></span><br><span class="line">labels = true_w[<span class="number">0</span>] * features[:, <span class="number">0</span>] + true_w[<span class="number">1</span>] * features[:, <span class="number">1</span>]<span class="comment"># 获取回归数据</span></span><br><span class="line">labels += torch.tensor(np.random.normal(<span class="number">0</span>, <span class="number">0.01</span>, size=labels.size()),</span><br><span class="line">                       dtype=torch.float32)<span class="comment"># 加入扰动</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对创建的数据进行可视化</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">use_svg_display</span>():</span><br><span class="line">    <span class="comment"># 用矢量图显示</span></span><br><span class="line">  display.set_matplotlib_formats(<span class="string">&#x27;svg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_figsize</span>(<span class="params">figsize=(<span class="params"><span class="number">3.5</span>, <span class="number">2.5</span></span>)</span>):</span><br><span class="line">    use_svg_display()</span><br><span class="line">    <span class="comment"># 设置图的尺寸</span></span><br><span class="line">    plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = figsize</span><br><span class="line">set_figsize()</span><br><span class="line">plt.scatter(features[:, <span class="number">1</span>].numpy(), labels.numpy(), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据迭代器，进行批量学习</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_iter</span>(<span class="params">batch_size, features, labels</span>):</span><br><span class="line">    <span class="comment"># batch_size是选取的每次学习的数据长度</span></span><br><span class="line">    <span class="comment"># features是数据特征</span></span><br><span class="line">    <span class="comment"># labels是数据标签</span></span><br><span class="line">    num_examples = <span class="built_in">len</span>(features)</span><br><span class="line">    indices = <span class="built_in">list</span>(<span class="built_in">range</span>(num_examples))<span class="comment"># 获取索引</span></span><br><span class="line">    random.shuffle(indices)<span class="comment"># 打乱索引</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_examples, batch_size):</span><br><span class="line">        <span class="comment"># 最后⼀次可能不⾜⼀个batch可利用min(i + batch_size,num_examples)进行拆解</span></span><br><span class="line">        <span class="comment"># 将indices[i:min(i + batch_size,num_examples)]转为LongTensor类型</span></span><br><span class="line">        j = torch.LongTensor(indices[i:<span class="built_in">min</span>(i + batch_size,num_examples)])</span><br><span class="line">        <span class="comment"># 利用yield关键字生成迭代器</span></span><br><span class="line">        <span class="keyword">yield</span> features.index_select(<span class="number">0</span>, j), labels.index_select(<span class="number">0</span>, j)</span><br><span class="line"><span class="comment"># 定义线性回归模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">linreg</span>(<span class="params">X,w,b</span>):</span><br><span class="line">    <span class="comment"># 利用torch.mm进行矩阵相乘</span></span><br><span class="line">    <span class="keyword">return</span> torch.mm(X,w) + b</span><br><span class="line"><span class="comment"># 定义平方误差</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">squared_loss</span>(<span class="params">y_hat, y</span>):</span><br><span class="line">    <span class="keyword">return</span> (y_hat - y.view(y_hat.size())) ** <span class="number">2</span> / <span class="number">2</span></span><br><span class="line"><span class="comment"># 随机小批量梯度下降法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sgd</span>(<span class="params">params, lr, batch_size</span>):</span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">        param.data -= lr * param.grad / batch_size</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 利用random初始化w</span></span><br><span class="line">    w = torch.tensor(np.random.normal(<span class="number">0</span>,<span class="number">0.01</span>,(num_inputs,<span class="number">1</span>)), dtype=torch.float32)</span><br><span class="line">    <span class="comment"># 初始化b</span></span><br><span class="line">    b = torch.zeros(<span class="number">1</span>, dtype=torch.float32)</span><br><span class="line">    <span class="comment"># 将w和b设置为可追踪操作，requires_grad=True</span></span><br><span class="line">    w.requires_grad_(requires_grad=<span class="literal">True</span>)</span><br><span class="line">    b.requires_grad_(requires_grad=<span class="literal">True</span>)</span><br><span class="line">    lr = <span class="number">0.03</span> <span class="comment"># 设置学习率</span></span><br><span class="line">    num_epochs = <span class="number">3</span> <span class="comment"># 设置学习轮数 </span></span><br><span class="line">    net = linreg <span class="comment"># 定义线性模型</span></span><br><span class="line">    loss = squared_loss <span class="comment"># 定义损失函数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="keyword">for</span> X,y <span class="keyword">in</span> data_iter(batch_size, features, labels): <span class="comment"># 从迭代器中选取每次batch的训练数据</span></span><br><span class="line">            l = loss(net(X,w,b),y).<span class="built_in">sum</span>() <span class="comment"># 求损失函数值</span></span><br><span class="line">            l.backward() <span class="comment"># 利用backward进行求导，得到的梯度会保存再w,b的grad属性中</span></span><br><span class="line">            sgd([w,b],lr,batch_size) <span class="comment"># 利用小批量梯度下降法进行更新</span></span><br><span class="line">            w.grad.data.zero_() <span class="comment"># grad.data.zero_()将梯度清零，不然梯度会累加</span></span><br><span class="line">            b.grad.data.zero_() <span class="comment"># grad.data.zero_()将梯度清零，不然梯度会累加</span></span><br><span class="line">        train_1 = loss(net(features,w,b),labels)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss %f&#x27;</span> % (epoch + <span class="number">1</span>, train_1.mean().item()))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>输出：</p><figure><img src="C:\Users\97196\Desktop\9699cc708a98e2ebcdef01e5ad0e9d3.jpg" alt="9699cc708a98e2ebcdef01e5ad0e9d3" /><figcaption>9699cc708a98e2ebcdef01e5ad0e9d3</figcaption></figure><h4 id="代码解读">代码解读</h4><p>​ 只对主体代码进行解读。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建数据迭代器，进行批量学习</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_iter</span>(<span class="params">batch_size, features, labels</span>):</span><br><span class="line">    <span class="comment"># batch_size是选取的每次学习的数据长度</span></span><br><span class="line">    <span class="comment"># features是数据特征</span></span><br><span class="line">    <span class="comment"># labels是数据标签</span></span><br><span class="line">    num_examples = <span class="built_in">len</span>(features)</span><br><span class="line">    indices = <span class="built_in">list</span>(<span class="built_in">range</span>(num_examples))<span class="comment"># 获取索引</span></span><br><span class="line">    random.shuffle(indices)<span class="comment"># 打乱索引</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_examples, batch_size):</span><br><span class="line">        <span class="comment"># 最后⼀次可能不⾜⼀个batch可利用min(i + batch_size,num_examples)进行拆解</span></span><br><span class="line">        <span class="comment"># 将indices[i:min(i + batch_size,num_examples)]转为LongTensor类型</span></span><br><span class="line">        j = torch.LongTensor(indices[i:<span class="built_in">min</span>(i + batch_size,num_examples)])</span><br><span class="line">        <span class="comment"># 利用yield关键字生成迭代器</span></span><br><span class="line">        <span class="keyword">yield</span> features.index_select(<span class="number">0</span>, j), labels.index_select(<span class="number">0</span>, j)</span><br></pre></td></tr></table></figure><p>​ <strong>data_iter</strong>是从原始数据中产生小批量<span class="math inline">\(\mathcal{B}\)</span>数据迭代器的函数。</p><p>​ 其中yield关键字是产生迭代器的关键字，具体可以查看<a href="https://juejin.cn/post/7142090372250861599">python基础查漏补缺 - 掘金 (juejin.cn)</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义线性回归模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">linreg</span>(<span class="params">X,w,b</span>):</span><br><span class="line">    <span class="comment"># 利用torch.mm进行矩阵相乘</span></span><br><span class="line">    <span class="keyword">return</span> torch.mm(X,w) + b</span><br><span class="line"><span class="comment"># 定义平方误差</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">squared_loss</span>(<span class="params">y_hat, y</span>):</span><br><span class="line">    <span class="keyword">return</span> (y_hat - y.view(y_hat.size())) ** <span class="number">2</span> / <span class="number">2</span></span><br></pre></td></tr></table></figure><p>​ <strong>linreg</strong>，<strong>squared_loss</strong>是进行前向传播的神经网络层</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> X,y <span class="keyword">in</span> data_iter(batch_size, features, labels): <span class="comment"># 从迭代器中选取每次batch的训练数据</span></span><br><span class="line">        l = loss(net(X,w,b),y).<span class="built_in">sum</span>() <span class="comment"># 求损失函数值</span></span><br><span class="line">        l.backward() <span class="comment"># 利用backward进行求导，得到的梯度会保存再w,b的grad属性中</span></span><br><span class="line">        sgd([w,b],lr,batch_size) <span class="comment"># 利用小批量梯度下降法进行更新</span></span><br><span class="line">        w.grad.data.zero_() <span class="comment"># grad.data.zero_()将梯度清零，不然梯度会累加</span></span><br><span class="line">        b.grad.data.zero_() <span class="comment"># grad.data.zero_()将梯度清零，不然梯度会累加</span></span><br><span class="line">    train_1 = loss(net(features,w,b),labels)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss %f&#x27;</span> % (epoch + <span class="number">1</span>, train_1.mean().item()))</span><br></pre></td></tr></table></figure><p>​ 上述流程是关键。</p><p>​ Step1：（正向传播）用loss(net(X,w,b),y).sum()求得最终损失值。</p><p>​ <strong>Step2：</strong>（反向传播）根据w，b定义了<strong>requires_grad=True</strong>可以进行梯度计算，并把计算储存在w，b中的grad属性。</p><p>​ Step3：利用小批量随机梯度下降法进行参数更新。</p><p>​ Step4：对w，b进行梯度清0，否则梯度会累加。</p><p>​ Step5：对选取的小批量数据完成Step1到Step4循环后，进行下一个epoch。</p><h4 id="线性回归的简洁实现">线性回归的简洁实现</h4><blockquote><p>torch.utils.data 模块提供了有关数据处理的⼯具</p><p>torch.nn 模块定义了⼤量神经⽹络的层</p><p>torch.nn.init 模块定义了各种初始化⽅法</p><p>torch.optim 模块提供了模型参数初始化的各种⽅法</p></blockquote><p>先上代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init<span class="comment"># 初始化模型参数</span></span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data <span class="comment"># 导入生成迭代器的库</span></span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line">torch.manual_seed(<span class="number">1</span>) <span class="comment"># 设置随机数种子</span></span><br><span class="line">torch.set_default_tensor_type(<span class="string">&#x27;torch.FloatTensor&#x27;</span>)<span class="comment"># 修改默认tensor类型</span></span><br><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">num_inputs = <span class="number">2</span></span><br><span class="line">num_examples = <span class="number">1000</span></span><br><span class="line">true_w = [<span class="number">2</span>, -<span class="number">3.4</span>]</span><br><span class="line">true_b = <span class="number">4.2</span></span><br><span class="line">features = torch.tensor(np.random.normal(<span class="number">0</span>,<span class="number">1</span>,(num_examples,num_inputs)),dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">labels = true_w[<span class="number">0</span>] * features[:, <span class="number">0</span>] + true_w[<span class="number">1</span>] * features[:, <span class="number">1</span>] + true_b</span><br><span class="line">labels += torch.tensor(np.random.normal(<span class="number">0</span>, <span class="number">0.01</span>, size=labels.size()), dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">10</span> <span class="comment"># 设置</span></span><br><span class="line">dataset = Data.TensorDataset(features, labels)</span><br><span class="line"><span class="comment"># 生成迭代器，shuffle为是否打乱，num_workers多线程</span></span><br><span class="line">data_iter= Data.DataLoader(dataset=dataset,batch_size=batch_size,shuffle=<span class="literal">True</span>,num_workers=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_feature</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearNet , self).__init__()<span class="comment"># 继承LinearNet中的初始化方式</span></span><br><span class="line">        self.linear= nn.Linear(n_feature,<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self ,x</span>):<span class="comment"># 正向传播</span></span><br><span class="line">        y= self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line">net = LinearNet(num_inputs)</span><br><span class="line"><span class="comment"># 初始化模型参数</span></span><br><span class="line">init.normal(net.linear.weight, mean=<span class="number">0.0</span>, std=<span class="number">0.01</span>)</span><br><span class="line">init.constant(net.linear.bias, val=<span class="number">0.0</span>)</span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line">loss = nn.MSELoss()</span><br><span class="line"><span class="comment"># 定义优化方式</span></span><br><span class="line">optimizer= optim.SGD(net.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">num_epochs = <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,num_epochs + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> X,y <span class="keyword">in</span> data_iter:</span><br><span class="line">        output = net(X)</span><br><span class="line">        l = loss(output , y.view(-<span class="number">1</span>,<span class="number">1</span>))<span class="comment"># 正向传播</span></span><br><span class="line">        optimizer.zero_grad()<span class="comment"># 梯度清0</span></span><br><span class="line">        l.backward()<span class="comment"># 计算梯度</span></span><br><span class="line">        optimizer.step()<span class="comment"># 更新参数</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss: %f&#x27;</span> %(epoch, l.item()))</span><br></pre></td></tr></table></figure><p>代码解读：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化模型参数</span></span><br><span class="line">init.normal(net.linear.weight, mean=<span class="number">0.0</span>, std=<span class="number">0.01</span>)</span><br><span class="line">init.constant(net.linear.bias, val=<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure><p>不进行初始化也可以，pytorch自带有参数初始化。</p><p><strong>优化器</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer= optim.SGD(net.parameters(), lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><p>optimizer中保存了net中的参数，因此当l.backward()执行的时候，梯度会存储在grad中，即在optimizer中，因此可以用step进行更新，注意此处的lr是对全局全部参数更新的学习率</p><p>如果想对某层网络的学习率进行调整，可以以下方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">optimizer =optim.SGD([</span><br><span class="line"> <span class="comment"># 如果对某个参数不指定学习率，就使⽤最外层的默认学习率</span></span><br><span class="line"> &#123;<span class="string">&#x27;params&#x27;</span>: net.subnet1.parameters()&#125;, <span class="comment"># lr=0.03</span></span><br><span class="line"> &#123;<span class="string">&#x27;params&#x27;</span>: net.subnet2.parameters(), <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.01</span>&#125;</span><br><span class="line"> ], lr=<span class="number">0.03</span>)</span><br></pre></td></tr></table></figure><p><strong>模型构建</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_feature</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearNet , self).__init__()<span class="comment"># 继承LinearNet中的初始化方式</span></span><br><span class="line">        self.linear= nn.Linear(n_feature,<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self ,x</span>):<span class="comment"># 正向传播</span></span><br><span class="line">        y= self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><p>此处模型的定义用了继承的方式，定义了类继承了线性模型。</p><p>其中forward会在net(X)执行的时候自动调用，因为nn.Module中定义了__call__，当net(X)执行时候会自动调用。</p><p>除了上述定义模型的方法还可以创建Sequential</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 写法一</span></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Linear(num_inputs, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 此处还可以传入其他层</span></span><br><span class="line">    )</span><br><span class="line"><span class="comment"># 写法二</span></span><br><span class="line">net = nn.Sequential()</span><br><span class="line">net.add_module(<span class="string">&#x27;linear&#x27;</span>, nn.Linear(num_inputs, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># net.add_module ......</span></span><br><span class="line"><span class="comment"># 写法三</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line">net = nn.Sequential(OrderedDict([</span><br><span class="line">          (<span class="string">&#x27;linear&#x27;</span>, nn.Linear(num_inputs, <span class="number">1</span>))</span><br><span class="line">          <span class="comment"># ......</span></span><br><span class="line">        ]))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line"><span class="built_in">print</span>(net[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><p>从上面的过程可以看出，一个完整的流程如下：</p><p>Step1：定义模型</p><p>Step2：传入数据进行前向传播，得到误差</p><p>Step3：反向传播计算梯度，更新梯度，回到St</p>]]></content>
      
      
      <categories>
          
          <category> 编程学习 </category>
          
          <category> pytorch学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
